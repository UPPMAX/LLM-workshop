# Day 1 Survey Analysis

## Overview

This analysis compares pre-course and post-course survey responses for Day 1 of the LLM workshop (November 2025).

## Confidence Rating Improvements

The following table shows the average confidence ratings (scale 1-5) for each learning outcome, comparing pre-course expectations with post-course assessments:

| Learning Outcome | Pre-Course Avg | Post-Course Avg | Improvement |
|------------------|----------------|-----------------|-------------|
| I know the tools available on Alvis for LLM inference | 1.77 | 3.95 | +2.18 |
| I know common datatypes relevant to LLMs | 2.23 | 3.95 | +1.72 |
| I know common ways of performing quantization | 1.73 | 3.40 | +1.67 |
| I know common formats in which LLMs are saved on disk | 2.10 | 3.75 | +1.65 |
| I know some tricks to reduce the computational and memory footprint of LLMs | 1.90 | 3.50 | +1.60 |
| I understand some elements in LLM names | 2.43 | 3.90 | +1.47 |
| I understand the categories in which LLMs are released | 2.63 | 4.00 | +1.37 |
| I know what to look for when selecting a language model for my use case | 2.33 | 3.70 | +1.37 |
| I understand the overall architecture of the Alvis compute cluster | 2.90 | 4.25 | +1.35 |
| I know how to check compatibility between models and hardware | 2.00 | 3.30 | +1.30 |
| I know the difference in needs of LLM training/fine-tuning/inference | 2.77 | 4.05 | +1.28 |
| I understand the OpenAI API | 2.43 | 3.50 | +1.07 |
| I know different ways to perform offline inference | 2.17 | 3.15 | +0.98 |
| I know why the Transformer architecture helped training LLMs | 2.97 | 3.95 | +0.98 |
| I can perform inference using LLM inference engine/server | 2.23 | 3.15 | +0.92 |
| I know some history and origins of current generative models with attention mechanism | 3.13 | 4.00 | +0.87 |
| I know the general structure of neural networks | 3.60 | 4.20 | +0.60 |

## Distribution Shifts

Detailed distribution of confidence ratings before and after the course:

### I know the tools available on Alvis for LLM inference

**Pre-course distribution** (n=30):
- Rating 1: 17 ( 56.7%) ███████████
- Rating 2:  6 ( 20.0%) ████
- Rating 3:  4 ( 13.3%) ██
- Rating 4:  3 ( 10.0%) ██
- Rating 5:  0 (  0.0%) 

**Post-course distribution** (n=20):
- Rating 1:  1 (  5.0%) █
- Rating 2:  1 (  5.0%) █
- Rating 3:  4 ( 20.0%) ████
- Rating 4:  6 ( 30.0%) ██████
- Rating 5:  8 ( 40.0%) ████████

### I know common datatypes relevant to LLMs

**Pre-course distribution** (n=30):
- Rating 1:  8 ( 26.7%) █████
- Rating 2: 10 ( 33.3%) ██████
- Rating 3: 10 ( 33.3%) ██████
- Rating 4:  1 (  3.3%) 
- Rating 5:  1 (  3.3%) 

**Post-course distribution** (n=20):
- Rating 1:  1 (  5.0%) █
- Rating 2:  1 (  5.0%) █
- Rating 3:  3 ( 15.0%) ███
- Rating 4:  8 ( 40.0%) ████████
- Rating 5:  7 ( 35.0%) ███████

### I know common ways of performing quantization

**Pre-course distribution** (n=30):
- Rating 1: 16 ( 53.3%) ██████████
- Rating 2: 10 ( 33.3%) ██████
- Rating 3:  1 (  3.3%) 
- Rating 4:  2 (  6.7%) █
- Rating 5:  1 (  3.3%) 

**Post-course distribution** (n=20):
- Rating 1:  2 ( 10.0%) ██
- Rating 2:  3 ( 15.0%) ███
- Rating 3:  3 ( 15.0%) ███
- Rating 4:  9 ( 45.0%) █████████
- Rating 5:  3 ( 15.0%) ███

### I know common formats in which LLMs are saved on disk

**Pre-course distribution** (n=30):
- Rating 1: 11 ( 36.7%) ███████
- Rating 2:  9 ( 30.0%) ██████
- Rating 3:  7 ( 23.3%) ████
- Rating 4:  2 (  6.7%) █
- Rating 5:  1 (  3.3%) 

**Post-course distribution** (n=20):
- Rating 1:  1 (  5.0%) █
- Rating 2:  2 ( 10.0%) ██
- Rating 3:  4 ( 20.0%) ████
- Rating 4:  7 ( 35.0%) ███████
- Rating 5:  6 ( 30.0%) ██████

### I know some tricks to reduce the computational and memory footprint of LLMs

**Pre-course distribution** (n=30):
- Rating 1: 13 ( 43.3%) ████████
- Rating 2: 11 ( 36.7%) ███████
- Rating 3:  4 ( 13.3%) ██
- Rating 4:  0 (  0.0%) 
- Rating 5:  2 (  6.7%) █

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  5 ( 25.0%) █████
- Rating 3:  5 ( 25.0%) █████
- Rating 4:  5 ( 25.0%) █████
- Rating 5:  5 ( 25.0%) █████

### I understand some elements in LLM names

**Pre-course distribution** (n=30):
- Rating 1: 10 ( 33.3%) ██████
- Rating 2:  3 ( 10.0%) ██
- Rating 3: 12 ( 40.0%) ████████
- Rating 4:  4 ( 13.3%) ██
- Rating 5:  1 (  3.3%) 

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  1 (  5.0%) █
- Rating 3:  6 ( 30.0%) ██████
- Rating 4:  7 ( 35.0%) ███████
- Rating 5:  6 ( 30.0%) ██████

### I understand the categories in which LLMs are released

**Pre-course distribution** (n=30):
- Rating 1:  3 ( 10.0%) ██
- Rating 2: 12 ( 40.0%) ████████
- Rating 3:  9 ( 30.0%) ██████
- Rating 4:  5 ( 16.7%) ███
- Rating 5:  1 (  3.3%) 

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  1 (  5.0%) █
- Rating 3:  5 ( 25.0%) █████
- Rating 4:  7 ( 35.0%) ███████
- Rating 5:  7 ( 35.0%) ███████

### I know what to look for when selecting a language model for my use case

**Pre-course distribution** (n=30):
- Rating 1:  7 ( 23.3%) ████
- Rating 2: 10 ( 33.3%) ██████
- Rating 3: 10 ( 33.3%) ██████
- Rating 4:  2 (  6.7%) █
- Rating 5:  1 (  3.3%) 

**Post-course distribution** (n=20):
- Rating 1:  1 (  5.0%) █
- Rating 2:  1 (  5.0%) █
- Rating 3:  5 ( 25.0%) █████
- Rating 4:  9 ( 45.0%) █████████
- Rating 5:  4 ( 20.0%) ████

### I understand the overall architecture of the Alvis compute cluster

**Pre-course distribution** (n=30):
- Rating 1:  3 ( 10.0%) ██
- Rating 2:  7 ( 23.3%) ████
- Rating 3: 12 ( 40.0%) ████████
- Rating 4:  6 ( 20.0%) ████
- Rating 5:  2 (  6.7%) █

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  0 (  0.0%) 
- Rating 3:  3 ( 15.0%) ███
- Rating 4:  9 ( 45.0%) █████████
- Rating 5:  8 ( 40.0%) ████████

### I know how to check compatibility between models and hardware

**Pre-course distribution** (n=30):
- Rating 1: 14 ( 46.7%) █████████
- Rating 2:  9 ( 30.0%) ██████
- Rating 3:  3 ( 10.0%) ██
- Rating 4:  1 (  3.3%) 
- Rating 5:  3 ( 10.0%) ██

**Post-course distribution** (n=20):
- Rating 1:  2 ( 10.0%) ██
- Rating 2:  3 ( 15.0%) ███
- Rating 3:  5 ( 25.0%) █████
- Rating 4:  7 ( 35.0%) ███████
- Rating 5:  3 ( 15.0%) ███

### I know the difference in needs of LLM training/fine-tuning/inference

**Pre-course distribution** (n=30):
- Rating 1:  6 ( 20.0%) ████
- Rating 2: 11 ( 36.7%) ███████
- Rating 3:  3 ( 10.0%) ██
- Rating 4:  4 ( 13.3%) ██
- Rating 5:  6 ( 20.0%) ████

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  3 ( 15.0%) ███
- Rating 3:  3 ( 15.0%) ███
- Rating 4:  4 ( 20.0%) ████
- Rating 5: 10 ( 50.0%) ██████████

### I understand the OpenAI API

**Pre-course distribution** (n=30):
- Rating 1: 10 ( 33.3%) ██████
- Rating 2:  5 ( 16.7%) ███
- Rating 3:  9 ( 30.0%) ██████
- Rating 4:  4 ( 13.3%) ██
- Rating 5:  2 (  6.7%) █

**Post-course distribution** (n=20):
- Rating 1:  1 (  5.0%) █
- Rating 2:  3 ( 15.0%) ███
- Rating 3:  5 ( 25.0%) █████
- Rating 4:  7 ( 35.0%) ███████
- Rating 5:  4 ( 20.0%) ████

### I know different ways to perform offline inference

**Pre-course distribution** (n=30):
- Rating 1: 13 ( 43.3%) ████████
- Rating 2:  6 ( 20.0%) ████
- Rating 3:  6 ( 20.0%) ████
- Rating 4:  3 ( 10.0%) ██
- Rating 5:  2 (  6.7%) █

**Post-course distribution** (n=20):
- Rating 1:  3 ( 15.0%) ███
- Rating 2:  3 ( 15.0%) ███
- Rating 3:  5 ( 25.0%) █████
- Rating 4:  6 ( 30.0%) ██████
- Rating 5:  3 ( 15.0%) ███

### I know why the Transformer architecture helped training LLMs

**Pre-course distribution** (n=30):
- Rating 1:  3 ( 10.0%) ██
- Rating 2: 11 ( 36.7%) ███████
- Rating 3:  5 ( 16.7%) ███
- Rating 4:  6 ( 20.0%) ████
- Rating 5:  5 ( 16.7%) ███

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  2 ( 10.0%) ██
- Rating 3:  5 ( 25.0%) █████
- Rating 4:  5 ( 25.0%) █████
- Rating 5:  8 ( 40.0%) ████████

### I can perform inference using LLM inference engine/server

**Pre-course distribution** (n=30):
- Rating 1: 14 ( 46.7%) █████████
- Rating 2:  4 ( 13.3%) ██
- Rating 3:  6 ( 20.0%) ████
- Rating 4:  3 ( 10.0%) ██
- Rating 5:  3 ( 10.0%) ██

**Post-course distribution** (n=20):
- Rating 1:  3 ( 15.0%) ███
- Rating 2:  3 ( 15.0%) ███
- Rating 3:  6 ( 30.0%) ██████
- Rating 4:  4 ( 20.0%) ████
- Rating 5:  4 ( 20.0%) ████

### I know some history and origins of current generative models with attention mechanism

**Pre-course distribution** (n=30):
- Rating 1:  2 (  6.7%) █
- Rating 2:  5 ( 16.7%) ███
- Rating 3: 12 ( 40.0%) ████████
- Rating 4:  9 ( 30.0%) ██████
- Rating 5:  2 (  6.7%) █

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  2 ( 10.0%) ██
- Rating 3:  2 ( 10.0%) ██
- Rating 4: 10 ( 50.0%) ██████████
- Rating 5:  6 ( 30.0%) ██████

### I know the general structure of neural networks

**Pre-course distribution** (n=30):
- Rating 1:  2 (  6.7%) █
- Rating 2:  4 ( 13.3%) ██
- Rating 3:  6 ( 20.0%) ████
- Rating 4: 10 ( 33.3%) ██████
- Rating 5:  8 ( 26.7%) █████

**Post-course distribution** (n=20):
- Rating 1:  0 (  0.0%) 
- Rating 2:  1 (  5.0%) █
- Rating 3:  3 ( 15.0%) ███
- Rating 4:  7 ( 35.0%) ███████
- Rating 5:  9 ( 45.0%) █████████

## Key Takeaways from Participant Feedback

Selected feedback from participants:

1. "exercises pace should be slower and better documented"

2. "Time for exercises too little. More time needed. More examples on the github repo as well please."

3. "More time spent on worked examples, instead of lecture style sections. Easier to digest how things work in practice that way."

4. "Today’s exercise felt extremely rushed, we were given only about five minutes to complete it, which was far too quick. For future sessions, it would be very helpful to allow more time so we can fully engage with the task.    Additionally, the explanation of the exercise was quite fast and somewhat ad-hoc, making it difficult to follow what was being done and why. Since it was the only hands-on part of the day, it would have been great to receive a clearer walkthrough and enough time to actually absorb the material.    I really hope that for the next exercises we can have a more structured explanation and more time to complete the tasks. This would make the hands-on portion much more valuable and easier to grasp."

5. "The instructions for the practical exercises are very incomplete. The super simple stuff in the beginning is clear but the actually useful exercises on running interference have incomplete commands in the provided material. If you’re not familiar to this environment and get a little stuck, then there is no way to catch up because the commands for the next step is no longer available since it was only shown on the screen and not included in the slides."

6. "The last two lectures were complicated, but I still have an unanswered question: given >20 "flavors" of the same LLM with different quantizations / Instruct / whatever, is there a method to choose which ONE FLAVOR I should use on Alvis, except by re-running my "typical task" for each of these flavors and manually examining them to score the performance?"

7. "Based on the workshop description I was expecting more hands-on sessions were the different concepts are actually practiced by the participants. In the inference session, the material about using vllm was poorly accessible and it was not clear what we were supposed to achieve. In the quantization session, I would have expected a more practical approach that shows me how I perform this and benchmark the result on my own. So far I don't think I have gained the expected practical skills for working with LLMs on the HPC system."

## Summary

- **Total learning outcomes tracked**: 17
- **Average improvement across all outcomes**: +1.32
- **Learning outcomes with positive improvement**: 17/17
- **Highest improvement**: "I know the tools available on Alvis for LLM inference" (+2.18)
