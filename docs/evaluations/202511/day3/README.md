# Day 3 Survey Analysis

## Overview

This analysis compares pre-course and post-course survey responses for Day 3 of the LLM workshop (November 2025).

## Confidence Rating Improvements

The following table shows the average confidence ratings (scale 1-5) for each learning outcome, comparing pre-course expectations with post-course assessments:

| Learning Outcome | Pre-Course Avg | Post-Course Avg | Improvement |
|------------------|----------------|-----------------|-------------|
| I am not afraid of finetuning an LLM on my dataset | 2.42 | 3.67 | +1.25 |
| I broadly know which evaluation metrics to evaluate on for my task | 2.42 | 3.67 | +1.25 |
| I know different finetuning techniques for LLMs | 2.42 | 3.58 | +1.17 |
| I know how LLMs make use of tools | 3.08 | 4.17 | +1.08 |
| I can evaluate LLMs on some common benchmarks | 2.33 | 3.42 | +1.08 |
| I know how to tune my hyperparameters | 2.42 | 3.33 | +0.92 |
| I know how to create a tool such that LLMs can use it | 2.92 | 3.75 | +0.83 |
| I can optimize my prompt for the LLM I am using | 3.08 | 3.83 | +0.75 |
| I understand the differences in context and prompt engineering | 3.42 | 4.00 | +0.58 |
| I know what various hyperparameters mean | 2.92 | 3.33 | +0.42 |

## Distribution Shifts

Detailed distribution of confidence ratings before and after the course:

### I am not afraid of finetuning an LLM on my dataset

**Pre-course distribution** (n=12):
- Rating 1:  4 ( 33.3%) ██████
- Rating 2:  4 ( 33.3%) ██████
- Rating 3:  1 (  8.3%) █
- Rating 4:  1 (  8.3%) █
- Rating 5:  2 ( 16.7%) ███

**Post-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  1 (  8.3%) █
- Rating 3:  4 ( 33.3%) ██████
- Rating 4:  1 (  8.3%) █
- Rating 5:  5 ( 41.7%) ████████

### I broadly know which evaluation metrics to evaluate on for my task

**Pre-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  6 ( 50.0%) ██████████
- Rating 3:  4 ( 33.3%) ██████
- Rating 4:  1 (  8.3%) █
- Rating 5:  0 (  0.0%) 

**Post-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  1 (  8.3%) █
- Rating 3:  2 ( 16.7%) ███
- Rating 4:  5 ( 41.7%) ████████
- Rating 5:  3 ( 25.0%) █████

### I know different finetuning techniques for LLMs

**Pre-course distribution** (n=12):
- Rating 1:  2 ( 16.7%) ███
- Rating 2:  5 ( 41.7%) ████████
- Rating 3:  3 ( 25.0%) █████
- Rating 4:  2 ( 16.7%) ███
- Rating 5:  0 (  0.0%) 

**Post-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  1 (  8.3%) █
- Rating 3:  2 ( 16.7%) ███
- Rating 4:  6 ( 50.0%) ██████████
- Rating 5:  2 ( 16.7%) ███

### I know how LLMs make use of tools

**Pre-course distribution** (n=12):
- Rating 1:  0 (  0.0%) 
- Rating 2:  3 ( 25.0%) █████
- Rating 3:  5 ( 41.7%) ████████
- Rating 4:  4 ( 33.3%) ██████
- Rating 5:  0 (  0.0%) 

**Post-course distribution** (n=12):
- Rating 1:  0 (  0.0%) 
- Rating 2:  0 (  0.0%) 
- Rating 3:  2 ( 16.7%) ███
- Rating 4:  6 ( 50.0%) ██████████
- Rating 5:  4 ( 33.3%) ██████

### I can evaluate LLMs on some common benchmarks

**Pre-course distribution** (n=12):
- Rating 1:  2 ( 16.7%) ███
- Rating 2:  6 ( 50.0%) ██████████
- Rating 3:  3 ( 25.0%) █████
- Rating 4:  0 (  0.0%) 
- Rating 5:  1 (  8.3%) █

**Post-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  1 (  8.3%) █
- Rating 3:  5 ( 41.7%) ████████
- Rating 4:  2 ( 16.7%) ███
- Rating 5:  3 ( 25.0%) █████

### I know how to tune my hyperparameters

**Pre-course distribution** (n=12):
- Rating 1:  2 ( 16.7%) ███
- Rating 2:  4 ( 33.3%) ██████
- Rating 3:  5 ( 41.7%) ████████
- Rating 4:  1 (  8.3%) █
- Rating 5:  0 (  0.0%) 

**Post-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  2 ( 16.7%) ███
- Rating 3:  3 ( 25.0%) █████
- Rating 4:  4 ( 33.3%) ██████
- Rating 5:  2 ( 16.7%) ███

### I know how to create a tool such that LLMs can use it

**Pre-course distribution** (n=12):
- Rating 1:  2 ( 16.7%) ███
- Rating 2:  2 ( 16.7%) ███
- Rating 3:  3 ( 25.0%) █████
- Rating 4:  5 ( 41.7%) ████████
- Rating 5:  0 (  0.0%) 

**Post-course distribution** (n=12):
- Rating 1:  0 (  0.0%) 
- Rating 2:  1 (  8.3%) █
- Rating 3:  3 ( 25.0%) █████
- Rating 4:  6 ( 50.0%) ██████████
- Rating 5:  2 ( 16.7%) ███

### I can optimize my prompt for the LLM I am using

**Pre-course distribution** (n=12):
- Rating 1:  2 ( 16.7%) ███
- Rating 2:  2 ( 16.7%) ███
- Rating 3:  2 ( 16.7%) ███
- Rating 4:  5 ( 41.7%) ████████
- Rating 5:  1 (  8.3%) █

**Post-course distribution** (n=12):
- Rating 1:  0 (  0.0%) 
- Rating 2:  0 (  0.0%) 
- Rating 3:  3 ( 25.0%) █████
- Rating 4:  8 ( 66.7%) █████████████
- Rating 5:  1 (  8.3%) █

### I understand the differences in context and prompt engineering

**Pre-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  1 (  8.3%) █
- Rating 3:  4 ( 33.3%) ██████
- Rating 4:  4 ( 33.3%) ██████
- Rating 5:  2 ( 16.7%) ███

**Post-course distribution** (n=12):
- Rating 1:  0 (  0.0%) 
- Rating 2:  0 (  0.0%) 
- Rating 3:  2 ( 16.7%) ███
- Rating 4:  8 ( 66.7%) █████████████
- Rating 5:  2 ( 16.7%) ███

### I know what various hyperparameters mean

**Pre-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  3 ( 25.0%) █████
- Rating 3:  6 ( 50.0%) ██████████
- Rating 4:  0 (  0.0%) 
- Rating 5:  2 ( 16.7%) ███

**Post-course distribution** (n=12):
- Rating 1:  1 (  8.3%) █
- Rating 2:  3 ( 25.0%) █████
- Rating 3:  2 ( 16.7%) ███
- Rating 4:  3 ( 25.0%) █████
- Rating 5:  3 ( 25.0%) █████

## Key Takeaways from Participant Feedback

Selected feedback from participants:

1. "I am very impressed by the quality of this course and have learned a lot. Thank you for organizing it!"

2. "For exercises: I know a lot of the commands are very basic, but as a new NAISS user it can be difficult to follow what e.g. the suggested working dir is (took a few exercises to learn this) or what I should put HF_HOME to, or exactly what file you are referring to in step 6 of an exercise, when it was downloaded in step 2 (in that case it would be great to refer to it by filename instead of something ambiguous like "take the server script and run it"). It's overall extremely basic, but it takes some mental load to figure out exactly what the reference is to when you're new.    I really liked Jayants exercises in the way that the setups were very clear! And I feel like I will understand the html output from the slides even in a couple of months due to the structural components.     Overall I'm very happy with this workshop, thank you for organizing it!"

3. "Thank you for the workshop!     An idea for the next iteration might be to include recordings of the intro we had in the morning day 1 along with some exercises to complete with just “hello world” stuff to submit jobs, launch jupyter, chainlit, etc. as additional prep for new users. That way you get a little more time to digest that before diving into the LLM content.  I have decent linux experience, I’m used to working on the command line etc, but it still took me a while to orient myself in the environment, day 2 and especially today things went a lot smoother."

4. "I spent the last few days sick in bed, so I just followed the workshop passively. Also, I dropped in and out depening on my energy levels. Sorry for that! But thanks a lot for the workshop! I think I got good overview of different LLM-related topics, and I now know what to look out for depening on my specific project needs."

5. "I couldn't attend the afternoon session on Friday, but I will have a look at the recordings when they become available. Thanks!"

## Summary

- **Total learning outcomes tracked**: 10
- **Average improvement across all outcomes**: +0.93
- **Learning outcomes with positive improvement**: 10/10
- **Highest improvement**: "I am not afraid of finetuning an LLM on my dataset" (+1.25)
